Measuring diversity in text has been previously achieved using topic
modeling on documents. In this approach, we are given a collection of
documents, from which we want to select the ones that are most
diverse. This can be achieved with good results by performing topic
modeling on those documents. Having a topic distribution for a
document, we can use a measure of diversity on that distribution,
e.g. Rao Diversity proposed in []. We consider a somewhat different
problem, where instead of documents, we have titles or sentences -
short sequences of usually 5 to 15 words. Now, performing topic
modeling directly on such data is not effective, because a single item
does not have sufficiently many words. One solution to this problem is
to group the items using some relevant meta-data information,
obtaining larger collections of words, that can be used for training a
topic model. However, if we have to train the topics on the same data,
that needs to be classified, then this approach will not support
online prediction, where new items come in one by one, which is
desirable in many practical applications. We propose a model which
addresses all of those issues, while also providing new insight into
human cognitive process.